"""
Servicio de integraciÃ³n con OpenAI para generar pruebas tÃ©cnicas
"""
import json
import os
from openai import OpenAI
from django.conf import settings


class OpenAIAssessmentService:
    """Servicio para generar preguntas tÃ©cnicas usando OpenAI"""
    
    def __init__(self):
        api_key = getattr(settings, 'OPENAI_API_KEY', os.getenv('OPENAI_API_KEY'))
        if not api_key:
            raise ValueError("OPENAI_API_KEY no estÃ¡ configurada en settings o variables de entorno")
        self.client = OpenAI(api_key=api_key)
        
    def generate_quiz_questions(self, topic, difficulty="MEDIUM", num_questions=10, language="es"):
        """
        Genera preguntas de cuestionario tÃ©cnico
        
        Args:
            topic: Tema tÃ©cnico (ej: "Python avanzado", "React Hooks", "Algoritmos")
            difficulty: EASY, MEDIUM, HARD
            num_questions: Cantidad de preguntas a generar
            language: Idioma de las preguntas (es, en)
            
        Returns:
            Lista de diccionarios con preguntas
        """
        difficulty_map = {
            "EASY": "fÃ¡cil, conceptos bÃ¡sicos",
            "MEDIUM": "intermedio, aplicaciÃ³n prÃ¡ctica",
            "HARD": "avanzado, casos complejos y optimizaciÃ³n"
        }
        
        prompt = f"""Genera {num_questions} preguntas de opciÃ³n mÃºltiple sobre {topic} de nivel {difficulty_map.get(difficulty, 'intermedio')}.

IMPORTANTE: Responde ÃšNICAMENTE con un JSON vÃ¡lido, sin texto adicional antes o despuÃ©s.

Formato JSON requerido:
{{
  "questions": [
    {{
      "question_text": "Â¿Pregunta aquÃ­?",
      "question_type": "MULTIPLE_CHOICE",
      "options": ["OpciÃ³n A", "OpciÃ³n B", "OpciÃ³n C", "OpciÃ³n D"],
      "correct_answer": "0",
      "explanation": "ExplicaciÃ³n detallada de por quÃ© la respuesta es correcta",
      "points": 10
    }}
  ]
}}

Reglas:
- Cada pregunta debe tener exactamente 4 opciones
- correct_answer debe ser el Ã­ndice (0-3) de la opciÃ³n correcta
- Las preguntas deben ser tÃ©cnicas y relevantes para {topic}
- Incluye una explicaciÃ³n clara de la respuesta correcta
- VarÃ­a la dificultad dentro del nivel {difficulty_map.get(difficulty)}
- Idioma: {'espaÃ±ol' if language == 'es' else 'inglÃ©s'}
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Eres un experto en crear evaluaciones tÃ©cnicas de programaciÃ³n. Respondes SOLO con JSON vÃ¡lido."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return result.get("questions", [])
            
        except Exception as e:
            raise Exception(f"Error al generar preguntas con OpenAI: {str(e)}")
    
    def generate_coding_challenges(self, topic, difficulty="MEDIUM", num_challenges=1, language="python"):
        """
        Genera desafÃ­os de cÃ³digo prÃ¡ctico con test_cases automÃ¡ticos para sandbox
        
        Args:
            topic: Tema tÃ©cnico
            difficulty: EASY, MEDIUM, HARD
            num_challenges: Cantidad de desafÃ­os (por defecto 1)
            language: Lenguaje de programaciÃ³n (python, javascript, java, etc.)
            
        Returns:
            Lista de diccionarios con desafÃ­os de cÃ³digo y test_cases
        """
        difficulty_map = {
            "EASY": "bÃ¡sico, sintaxis fundamental",
            "MEDIUM": "intermedio, estructuras de datos y algoritmos",
            "HARD": "avanzado, optimizaciÃ³n y patrones complejos"
        }
        
        # Ejemplos de sintaxis segÃºn lenguaje
        language_examples = {
            "python": {
                "snippet": "def solution(param):\\n    # Tu cÃ³digo aquÃ­\\n    pass",
                "input_example": '"[1, 2, 3]"',
                "output_example": '"6"',
                "note": "Test_cases para Python sandbox - formato JSON estÃ¡ndar",
                "example_one_param": '{"input": "[1, 2, 3]", "expected_output": "6"}',
                "example_multi_param": '{"input": "[[1, 2, 3], 5]", "expected_output": "[1, 2, 3, 5]"}'
            },
            "javascript": {
                "snippet": "function solution(param) {\\n  // Tu cÃ³digo aquÃ­\\n}",
                "input_example": '"[1, 2, 3]"',
                "output_example": '"6"',
                "note": "Test_cases para JavaScript sandbox - formato JSON estÃ¡ndar",
                "example_one_param": '{"input": "[1, 2, 3]", "expected_output": "6"}',
                "example_multi_param": '{"input": "[[1, 2, 3], 5]", "expected_output": "[1, 2, 3, 5]"}'
            },
            "java": {
                "snippet": "public class Solution {\\n  public static int solution(int[] param) {\\n    // Tu cÃ³digo aquÃ­\\n    return 0;\\n  }\\n}",
                "input_example": '"[1, 2, 3]"',
                "output_example": '"6"',
                "note": "Test_cases para Java sandbox - formato JSON estÃ¡ndar",
                "example_one_param": '{"input": "[1, 2, 3]", "expected_output": "6"}',
                "example_multi_param": '{"input": "[[1, 2, 3], 5]", "expected_output": "[1, 2, 3, 5]"}'
            }
        }
        
        lang_info = language_examples.get(language.lower(), language_examples["python"])
        
        prompt = f"""Genera {num_challenges} desafÃ­os de programaciÃ³n en {language} sobre {topic} de nivel {difficulty_map.get(difficulty, 'intermedio')}.

ðŸŽ¯ OBJETIVO: Crear desafÃ­os educativos con test_cases que se ejecutarÃ¡n en un SANDBOX REAL.

IMPORTANTE: Responde ÃšNICAMENTE con un JSON vÃ¡lido, sin texto adicional.

Formato JSON requerido:
{{
  "challenges": [
    {{
      "question_text": "DescripciÃ³n clara del problema a resolver",
      "question_type": "CODE",
      "programming_language": "{language}",
      "code_snippet": "{lang_info['snippet']}",
      "test_cases": [
        {{
          "description": "DescripciÃ³n del caso de prueba",
          "input": "STRING JSON con los parÃ¡metros",
          "expected_output": "STRING JSON con el resultado esperado"
        }}
      ],
      "explanation": "ExplicaciÃ³n de la soluciÃ³n Ã³ptima",
      "points": 20
    }}
  ]
}}

ðŸ”´ REGLAS CRÃTICAS PARA TEST_CASES (muy importante):

1. **Cantidad**: Genera MÃNIMO 4 test_cases, IDEAL 5-6 test_cases por desafÃ­o

2. **Cobertura**: Los test_cases DEBEN cubrir:
   - âœ… Caso bÃ¡sico/feliz (entrada tÃ­pica)
   - âœ… Caso edge (array vacÃ­o, string vacÃ­o, null, 0, etc.)
   - âœ… Caso con mÃºltiples elementos
   - âœ… Caso lÃ­mite (nÃºmeros grandes, strings largos)
   - âœ… Caso especial del dominio del problema

3. **Formato de input y expected_output** (MUY IMPORTANTE):
   - AMBOS deben ser STRINGS JSON vÃ¡lidos
   - Para UN parÃ¡metro:
     * NÃºmero: "42" o "3.14"
     * String: "\\"texto\\"" (con escapes)
     * Array: "[1, 2, 3]"
     * Boolean: "true" o "false"
     * Null: "null"
   - Para MÃšLTIPLES parÃ¡metros: usar un ARRAY que contenga todos los parÃ¡metros:
     * Dos nÃºmeros: "[5, 10]"
     * Array y nÃºmero: "[[1, 2, 3, 4, 5], 6]"
     * String y nÃºmero: "[\\"hello\\", 3]"
     * Tres parÃ¡metros: "[param1, param2, param3]"
   
   âš ï¸ REGLA CRÃTICA: Si la funciÃ³n recibe mÃºltiples parÃ¡metros, el input DEBE ser un array: "[param1, param2]"
   âŒ INCORRECTO: "[1, 2, 3], 6" (esto NO es JSON vÃ¡lido)
   âœ… CORRECTO: "[[1, 2, 3], 6]" (array con dos elementos)

4. **Nota para {language}**: {lang_info['note']}

5. **code_snippet**: Debe ser una plantilla inicial Ãºtil pero sin resolver el problema

6. **Problemas realistas**: Crea desafÃ­os educativos, prÃ¡cticos y relevantes para {topic}

EJEMPLO CORRECTO ({language.upper()} - UN PARÃMETRO):
{{
  "challenges": [
    {{
      "question_text": "Crea una funciÃ³n que sume todos los nÃºmeros pares de un array",
      "question_type": "CODE",
      "programming_language": "{language}",
      "code_snippet": "{lang_info['snippet']}",
      "test_cases": [
        {{
          "description": "Array con nÃºmeros mixtos",
          "input": "[1, 2, 3, 4, 5, 6]",
          "expected_output": "12"
        }},
        {{
          "description": "Array vacÃ­o",
          "input": "[]",
          "expected_output": "0"
        }},
        {{
          "description": "Solo nÃºmeros impares",
          "input": "[1, 3, 5, 7]",
          "expected_output": "0"
        }},
        {{
          "description": "Solo nÃºmeros pares",
          "input": "[2, 4, 6, 8]",
          "expected_output": "20"
        }},
        {{
          "description": "Array con un solo elemento par",
          "input": "[10]",
          "expected_output": "10"
        }},
        {{
          "description": "Array con nÃºmeros negativos",
          "input": "[-4, -2, 1, 3]",
          "expected_output": "-6"
        }}
      ],
      "explanation": "La soluciÃ³n Ã³ptima usa filter() para nÃºmeros pares y reduce() para sumar. Complejidad O(n) temporal, O(1) espacial.",
      "points": 20
    }}
  ]
}}

EJEMPLO CORRECTO ({language.upper()} - DOS PARÃMETROS):
{{
  "challenges": [
    {{
      "question_text": "Crea una funciÃ³n que filtre nÃºmeros pares de un array y retorne solo los primeros N elementos",
      "question_type": "CODE",
      "programming_language": "{language}",
      "code_snippet": "{lang_info['snippet']}",
      "test_cases": [
        {{
          "description": "Array con nÃºmeros mixtos y lÃ­mite 2",
          "input": "[[1, 2, 3, 4, 5, 6], 2]",
          "expected_output": "[2, 4]"
        }},
        {{
          "description": "Array vacÃ­o",
          "input": "[[], 3]",
          "expected_output": "[]"
        }},
        {{
          "description": "LÃ­mite mayor que pares disponibles",
          "input": "[[2, 4, 6], 10]",
          "expected_output": "[2, 4, 6]"
        }},
        {{
          "description": "Solo impares con lÃ­mite",
          "input": "[[1, 3, 5], 2]",
          "expected_output": "[]"
        }}
      ],
      "explanation": "Filtrar los pares y luego usar slice(0, limite). Complejidad O(n).",
      "points": 20
    }}
  ]
}}

âš ï¸ VERIFICACIÃ“N FINAL:
- Cada test_case tiene "description", "input" (string JSON), "expected_output" (string JSON)
- Los valores de input y expected_output estÃ¡n entre comillas y son strings JSON vÃ¡lidos
- Hay al menos 4-6 test_cases por desafÃ­o
- Los test_cases cubren casos normales, edge cases y casos lÃ­mite
- El nivel de dificultad es {difficulty_map.get(difficulty)}
- Los test_cases son COMPATIBLES con sandbox de {language} (Piston API, e0.gg, etc.)
- El formato de input/output es UNIVERSAL y funciona en cualquier sandbox

IMPORTANTE: Los test_cases generados deben ser ejecutables en sandboxes reales para {language}.
El formato JSON debe ser compatible con APIs de ejecuciÃ³n de cÃ³digo como Piston API.

Ahora genera los {num_challenges} desafÃ­os sobre {topic} en {language}:
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"Eres un experto en crear desafÃ­os de programaciÃ³n en {language}. Respondes SOLO con JSON vÃ¡lido."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return result.get("challenges", [])
            
        except Exception as e:
            raise Exception(f"Error al generar desafÃ­os con OpenAI: {str(e)}")
    
    def evaluate_code_answer(self, question_text, candidate_code, test_cases, language="python", difficulty="MEDIUM"):
        """
        EvalÃºa una respuesta de cÃ³digo usando OpenAI
        
        Args:
            question_text: Enunciado de la pregunta
            candidate_code: CÃ³digo enviado por el candidato
            test_cases: Lista de casos de prueba
            language: Lenguaje de programaciÃ³n
            difficulty: Nivel de dificultad (EASY, MEDIUM, HARD)
            
        Returns:
            Dict con evaluaciÃ³n y feedback
        """
        
        # Mapeo de dificultad a criterios de evaluaciÃ³n
        difficulty_criteria = {
            "EASY": {
                "funcionalidad": 70,
                "correctitud": 15,
                "legibilidad": 10,
                "eficiencia": 5,
                "min_score": 80,  # Si pasa todos los tests
                "description": "nivel BÃSICO/FÃCIL"
            },
            "MEDIUM": {
                "funcionalidad": 60,
                "correctitud": 20,
                "legibilidad": 10,
                "eficiencia": 10,
                "min_score": 75,  # Si pasa todos los tests
                "description": "nivel INTERMEDIO"
            },
            "HARD": {
                "funcionalidad": 50,
                "correctitud": 25,
                "legibilidad": 10,
                "eficiencia": 15,
                "min_score": 70,  # Si pasa todos los tests
                "description": "nivel AVANZADO"
            }
        }
        
        criteria = difficulty_criteria.get(difficulty, difficulty_criteria["MEDIUM"])
        
        prompt = f"""EvalÃºa el siguiente cÃ³digo del candidato para un ejercicio de {criteria['description']}:

PREGUNTA:
{question_text}

CÃ“DIGO DEL CANDIDATO ({language}):
```{language}
{candidate_code}
```

CASOS DE PRUEBA:
{json.dumps(test_cases, indent=2)}

ðŸŽ¯ ESCALA DE PUNTAJES QUE DEBES USAR:
- Si el cÃ³digo funciona y pasa TODOS los tests â†’ MÃNIMO {criteria['min_score']}% (hasta 100%)
- Si el cÃ³digo funciona y pasa la mayorÃ­a de tests â†’ 60-{criteria['min_score']-1}%
- Si el cÃ³digo funciona parcialmente â†’ 40-59%
- Si el cÃ³digo tiene errores graves â†’ 0-39%

ðŸ“Š CRITERIOS (usa estos pesos):
1. FUNCIONALIDAD ({criteria['funcionalidad']}%): Â¿Funciona? Â¿Pasa los tests?
2. CORRECTITUD ({criteria['correctitud']}%): Â¿La lÃ³gica es correcta?
3. LEGIBILIDAD ({criteria['legibilidad']}%): Â¿Es claro?
4. EFICIENCIA ({criteria['eficiencia']}%): Â¿Es razonable?

âš ï¸ REGLAS OBLIGATORIAS:
âœ… Si "is_correct": true â†’ el "score_percentage" DEBE ser MÃNIMO {criteria['min_score']}%
âœ… Si TODOS los "test_results" tienen "passed": true â†’ MÃNIMO {criteria['min_score']}%
âœ… NO seas demasiado estricto con cÃ³digo que funciona correctamente
âœ… Este es {criteria['description']}, ajusta expectativas segÃºn el nivel

Responde SOLO con JSON:
{{
  "is_correct": true/false,
  "score_percentage": NÃšMERO_ENTRE_0_Y_100,
  "feedback": "AnÃ¡lisis del cÃ³digo destacando fortalezas primero",
  "strengths": ["fortaleza 1", "fortaleza 2"],
  "improvements": ["sugerencia 1", "sugerencia 2"],
  "test_results": [
    {{"test_case": 1, "passed": true/false, "message": "resultado del test 1"}},
    {{"test_case": 2, "passed": true/false, "message": "resultado del test 2"}}
  ]
}}

RECORDATORIO FINAL: Si marcas "is_correct": true, el score_percentage NO puede ser menor a {criteria['min_score']}."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": f"Eres un evaluador de cÃ³digo {language}. REGLA CRÃTICA: Si el cÃ³digo funciona correctamente (is_correct=true), el score_percentage DEBE ser MÃNIMO {criteria['min_score']}%. Si todos los tests pasan, MÃNIMO {criteria['min_score']}%. Respondes SOLO JSON vÃ¡lido. SÃ© JUSTO y GENEROSO con cÃ³digo funcional."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,  # MÃ¡s determinÃ­stico para puntajes consistentes
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # âš¡âš¡âš¡ VALIDACIÃ“N ULTRA ROBUSTA: MÃšLTIPLES CAPAS DE VERIFICACIÃ“N âš¡âš¡âš¡
            score = result.get("score_percentage", 0)
            is_correct = result.get("is_correct", False)
            test_results = result.get("test_results", [])
            
            # Contar tests que pasaron
            passed_count = 0
            total_count = len(test_results) if test_results else 0
            if test_results:
                passed_count = sum(1 for t in test_results if t.get("passed", False))
            
            all_tests_passed = (total_count > 0 and passed_count == total_count)
            
            # ðŸ”´ CAPA 1: Si is_correct es true, FORZAR puntaje mÃ­nimo
            if is_correct:
                if score < criteria["min_score"]:
                    result["score_percentage"] = criteria["min_score"]
                    result["feedback"] = f"âœ… CÃ³digo correcto que resuelve el problema. {result.get('feedback', '')}"
            
            # ðŸ”´ CAPA 2: Si todos los tests pasaron, FORZAR puntaje mÃ­nimo
            if all_tests_passed:
                if score < criteria["min_score"]:
                    result["score_percentage"] = criteria["min_score"]
                    result["is_correct"] = True
                    result["feedback"] = f"âœ… TODOS los tests pasaron ({passed_count}/{total_count}). {result.get('feedback', '')}"
            
            # ðŸ”´ CAPA 3: Si pasa mÃ¡s del 80% de tests, dar al menos 70%
            if total_count > 0:
                pass_rate = (passed_count / total_count) * 100
                if pass_rate >= 80 and score < 70:
                    result["score_percentage"] = max(70, score)
                    result["is_correct"] = pass_rate == 100
            
            # ðŸ”´ CAPA 4: VerificaciÃ³n final cruzada
            final_score = result.get("score_percentage", 0)
            final_is_correct = result.get("is_correct", False)
            
            if final_is_correct and final_score < criteria["min_score"]:
                result["score_percentage"] = criteria["min_score"]
            
            if all_tests_passed and final_score < criteria["min_score"]:
                result["score_percentage"] = criteria["min_score"]
                result["is_correct"] = True
            
            # ðŸ”´ CAPA 5: GarantÃ­a absoluta - Ãºltima verificaciÃ³n
            ultimate_score = result.get("score_percentage", 0)
            if all_tests_passed and ultimate_score < criteria["min_score"]:
                # Si TODOS los tests pasaron, NO PUEDE ser menos del mÃ­nimo
                result["score_percentage"] = criteria["min_score"]
                result["is_correct"] = True
                print(f"âš ï¸ CORRECCIÃ“N FORZADA: Score original {score}% -> {criteria['min_score']}% (todos los tests pasaron)")
            
            return result
            
        except Exception as e:
            raise Exception(f"Error al evaluar cÃ³digo con OpenAI: {str(e)}")
    
    def analyze_application_for_assessment(self, application_id):
        """
        Analiza una aplicaciÃ³n (candidato + proyecto) y sugiere parÃ¡metros para crear una evaluaciÃ³n
        
        Args:
            application_id: ID de la Application a analizar
            
        Returns:
            Dict con sugerencias para crear evaluaciÃ³n tÃ©cnica
        """
        from recruiting.models import Application
        from projects.models import Project
        from django.contrib.auth.models import User
        import datetime
        
        try:
            # 1. Obtener la aplicaciÃ³n
            application = Application.objects.select_related('candidate', 'project').get(id=application_id)
            project = application.project
            candidate = application.candidate
            
            # 2. Extraer informaciÃ³n relevante
            required_skills = project.required_skills if hasattr(project, 'required_skills') else []
            extracted_data = application.extracted if application.extracted else {}
            candidate_skills = extracted_data.get('skills', [])
            experience_years = extracted_data.get('experience_years', 0)
            
            # Obtener texto del CV (primeros 500 caracteres)
            cv_preview = ""
            if application.parsed_text:
                cv_preview = application.parsed_text[:500]
            
            # 3. Construir prompt para OpenAI
            prompt = f"""Eres un experto en recursos humanos tÃ©cnicos. Analiza la siguiente informaciÃ³n y sugiere parÃ¡metros Ã³ptimos para una evaluaciÃ³n tÃ©cnica.

PROYECTO:
- TÃ­tulo: {project.title}
- DescripciÃ³n: {project.description[:200] if project.description else 'No disponible'}
- Skills requeridos: {', '.join(required_skills) if required_skills else 'No especificados'}
- Prioridad: {project.priority if hasattr(project, 'priority') else 'Media'}

CANDIDATO:
- Username: {candidate.username}
- AÃ±os de experiencia detectados: {experience_years}
- Skills del CV: {', '.join(candidate_skills) if candidate_skills else 'No detectados'}
- Match score con proyecto: {application.match_score}%
- Resumen CV: {cv_preview if cv_preview else 'No disponible'}

CONTEXTO ADICIONAL:
- Estado aplicaciÃ³n: {application.status}
- Fecha aplicaciÃ³n: {application.created_at.strftime('%Y-%m-%d') if application.created_at else 'N/A'}

INSTRUCCIONES:
BasÃ¡ndote en el anÃ¡lisis anterior, sugiere:
1. **TÃ­tulo descriptivo** para la evaluaciÃ³n (mÃ¡x 100 caracteres)
2. **DescripciÃ³n breve** explicando enfoque (mÃ¡x 200 caracteres)
3. **Tipo de evaluaciÃ³n**: "QUIZ" (preguntas teÃ³ricas) o "CODING" (prueba de cÃ³digo)
4. **Dificultad**: "EASY" (junior/bÃ¡sico), "MEDIUM" (mid-level/intermedio), "HARD" (senior/avanzado)
5. **Tiempo en minutos**: entre 30-120 segÃºn complejidad
6. **Score mÃ­nimo para aprobar**: entre 60-85%
7. **NÃºmero de preguntas**: 5-15 (menos para CODING, mÃ¡s para QUIZ)
8. **Lenguaje de programaciÃ³n** principal (si tipo es CODING)
9. **Nivel de experiencia del candidato**: "junior", "intermediate", "senior"
10. **Complejidad del proyecto**: "low", "medium", "high"
11. **Skills detectados** mÃ¡s relevantes para esta evaluaciÃ³n

CRITERIOS DE DECISIÃ“N:
- Si match_score >= 80% â†’ EASY (candidato califica bien)
- Si match_score 60-79% â†’ MEDIUM (candidato promedio)
- Si match_score < 60% â†’ HARD (evaluar mÃ¡s a fondo)
- Si required_skills incluye lenguajes de programaciÃ³n â†’ CODING
- Si required_skills son principalmente soft skills o teÃ³ricos â†’ QUIZ
- Ajustar tiempo segÃºn dificultad: EASY=30-45min, MEDIUM=60min, HARD=90-120min
- Score mÃ­nimo: EASY=65%, MEDIUM=70%, HARD=75%

RESPONDE EN JSON con esta estructura EXACTA:
{{
  "suggested_title": "...",
  "suggested_description": "...",
  "suggested_type": "QUIZ",
  "suggested_difficulty": "MEDIUM",
  "suggested_time_minutes": 60,
  "suggested_passing_score": 70,
  "suggested_num_questions": 10,
  "suggested_programming_language": "JavaScript",
  "difficulty_reason": "ExplicaciÃ³n de por quÃ© esta dificultad es apropiada",
  "time_reason": "ExplicaciÃ³n de por quÃ© este tiempo es adecuado",
  "score_reason": "ExplicaciÃ³n del score mÃ­nimo sugerido",
  "type_reason": "ExplicaciÃ³n de por quÃ© QUIZ o CODING",
  "detected_skills": ["skill1", "skill2", "skill3"],
  "candidate_experience_level": "intermediate",
  "project_complexity": "medium"
}}"""

            # 4. Llamar a OpenAI
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "Eres un experto en recursos humanos tÃ©cnicos especializado en crear evaluaciones. Respondes ÃšNICAMENTE con JSON vÃ¡lido."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # Validar y normalizar resultado
            result['application_id'] = application_id
            result['analyzed_at'] = datetime.datetime.now().isoformat()
            
            return result
            
        except Application.DoesNotExist:
            raise ValueError(f"Application {application_id} no encontrada")
        except Exception as e:
            # Si OpenAI falla, usar lÃ³gica de fallback
            print(f"âš ï¸ OpenAI fallÃ³, usando fallback: {str(e)}")
            return self._get_fallback_suggestions(application_id)
    
    def _get_fallback_suggestions(self, application_id):
        """
        LÃ³gica de fallback si OpenAI no estÃ¡ disponible
        Usa reglas heurÃ­sticas para generar sugerencias
        """
        from recruiting.models import Application
        import datetime
        
        try:
            application = Application.objects.select_related('candidate', 'project').get(id=application_id)
            project = application.project
            
            # Determinar dificultad basada en match_score
            if application.match_score >= 80:
                difficulty = "EASY"
                passing_score = 65
                time_minutes = 30
            elif application.match_score >= 60:
                difficulty = "MEDIUM"
                passing_score = 70
                time_minutes = 60
            else:
                difficulty = "HARD"
                passing_score = 75
                time_minutes = 90
            
            # Determinar tipo basado en skills requeridos
            required_skills = project.required_skills if hasattr(project, 'required_skills') else []
            coding_keywords = ['react', 'python', 'java', 'javascript', 'node', 'django', 'angular', 
                             'vue', 'php', 'ruby', 'go', 'rust', 'c++', 'c#', 'swift', 'kotlin']
            has_coding = any(
                any(keyword in str(skill).lower() for keyword in coding_keywords)
                for skill in required_skills
            )
            
            assessment_type = "CODING" if has_coding else "QUIZ"
            num_questions = 5 if assessment_type == "CODING" else 10
            
            # Detectar lenguaje principal
            programming_language = "JavaScript"
            for skill in required_skills:
                skill_lower = str(skill).lower()
                if 'python' in skill_lower or 'django' in skill_lower:
                    programming_language = "Python"
                    break
                elif 'java' in skill_lower and 'javascript' not in skill_lower:
                    programming_language = "Java"
                    break
                elif 'react' in skill_lower or 'node' in skill_lower or 'javascript' in skill_lower:
                    programming_language = "JavaScript"
                    break
            
            # Determinar nivel de experiencia
            extracted = application.extracted if application.extracted else {}
            experience_years = extracted.get('experience_years', 0)
            if experience_years < 2:
                candidate_experience = "junior"
            elif experience_years < 5:
                candidate_experience = "intermediate"
            else:
                candidate_experience = "senior"
            
            # Complejidad del proyecto
            if project.priority <= 2:
                project_complexity = "high"
            elif project.priority <= 3:
                project_complexity = "medium"
            else:
                project_complexity = "low"
            
            # Detectar skills relevantes
            detected_skills = required_skills[:5] if required_skills else ["No especificados"]
            
            return {
                "suggested_title": f"EvaluaciÃ³n {project.title}",
                "suggested_description": f"EvaluaciÃ³n tÃ©cnica para proyecto {project.title} - Nivel {difficulty.lower()}",
                "suggested_type": assessment_type,
                "suggested_difficulty": difficulty,
                "suggested_time_minutes": time_minutes,
                "suggested_passing_score": passing_score,
                "suggested_num_questions": num_questions,
                "suggested_programming_language": programming_language if assessment_type == "CODING" else None,
                "difficulty_reason": f"Match score de {application.match_score}% sugiere nivel {difficulty}",
                "time_reason": f"Dificultad {difficulty} requiere aproximadamente {time_minutes} minutos",
                "score_reason": f"Score mÃ­nimo de {passing_score}% apropiado para nivel {difficulty}",
                "type_reason": f"{'Skills de programaciÃ³n detectados' if has_coding else 'Skills principalmente teÃ³ricos'} sugieren {assessment_type}",
                "detected_skills": detected_skills,
                "candidate_experience_level": candidate_experience,
                "project_complexity": project_complexity,
                "application_id": application_id,
                "analyzed_at": datetime.datetime.now().isoformat(),
                "fallback_used": True
            }
            
        except Application.DoesNotExist:
            raise ValueError(f"Application {application_id} no encontrada")
        except Exception as e:
            raise Exception(f"Error en fallback: {str(e)}")
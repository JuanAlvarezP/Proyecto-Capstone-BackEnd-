"""
Servicio de integraci√≥n con OpenAI para generar pruebas t√©cnicas
"""
import json
import os
from openai import OpenAI
from django.conf import settings


class OpenAIAssessmentService:
    """Servicio para generar preguntas t√©cnicas usando OpenAI"""
    
    def __init__(self):
        api_key = getattr(settings, 'OPENAI_API_KEY', os.getenv('OPENAI_API_KEY'))
        if not api_key:
            raise ValueError("OPENAI_API_KEY no est√° configurada en settings o variables de entorno")
        self.client = OpenAI(api_key=api_key)
        
    def generate_quiz_questions(self, topic, difficulty="MEDIUM", num_questions=10, language="es", include_code_snippets=False):
        """
        Genera preguntas de cuestionario t√©cnico
        
        Args:
            topic: Tema t√©cnico (ej: "Python avanzado", "React Hooks", "Algoritmos")
            difficulty: EASY, MEDIUM, HARD
            num_questions: Cantidad de preguntas a generar
            language: Idioma de las preguntas (es, en)
            include_code_snippets: Si True, genera preguntas con fragmentos de c√≥digo
            
        Returns:
            Lista de diccionarios con preguntas
        """
        difficulty_map = {
            "EASY": {
                "description": "nivel B√ÅSICO/JUNIOR",
                "details": "Conceptos fundamentales, sintaxis b√°sica, definiciones est√°ndar",
                "min_time_per_question": 2,  # minutos
                "max_time_per_question": 3
            },
            "MEDIUM": {
                "description": "nivel INTERMEDIO/MID-LEVEL",
                "details": "Aplicaci√≥n pr√°ctica, an√°lisis de c√≥digo, resoluci√≥n de problemas reales, comparaci√≥n de enfoques, debugging",
                "min_time_per_question": 3,
                "max_time_per_question": 5
            },
            "HARD": {
                "description": "nivel AVANZADO/SENIOR",
                "details": "Optimizaci√≥n, arquitectura, patrones de dise√±o, casos edge complejos, an√°lisis de complejidad, trade-offs",
                "min_time_per_question": 5,
                "max_time_per_question": 7
            }
        }
        
        diff_info = difficulty_map.get(difficulty, difficulty_map["MEDIUM"])
        suggested_time = (diff_info["min_time_per_question"] + diff_info["max_time_per_question"]) / 2 * num_questions
        
        # Instrucciones adicionales para code_snippets
        code_instructions = ""
        code_example = ""
        if include_code_snippets:
            code_instructions = f"""

üî• GENERACI√ìN DE FRAGMENTOS DE C√ìDIGO (IMPORTANTE):
- Se requiere que TODAS o la MAYOR√çA de las preguntas incluyan fragmentos de c√≥digo
- Para cada pregunta que requiera c√≥digo, DEBES incluir AMBOS campos:
  * "question_text": La pregunta que hace referencia al c√≥digo
  * "code_snippet": El fragmento de c√≥digo completo y funcional
- El code_snippet debe ser c√≥digo REAL, ejecutable y relevante para {topic}
- La pregunta puede preguntar sobre: salida, comportamiento, errores, optimizaci√≥n, etc.
- El c√≥digo debe ser claro, bien formateado y sin errores de sintaxis
- M√çNIMO {int(num_questions * 0.6)} preguntas deben incluir code_snippet"""
            
            code_example = f"""
EJEMPLO DE PREGUNTA CON C√ìDIGO:
{{
  "question_text": "¬øCu√°l es la salida del siguiente c√≥digo?",
  "code_snippet": "def suma(a, b):\\n    return a + b\\n\\nresultado = suma(3, 5)\\nprint(resultado)",
  "question_type": "MULTIPLE_CHOICE",
  "options": ["3", "5", "8", "Error"],
  "correct_answer": "2",
  "explanation": "La funci√≥n suma recibe 3 y 5 como par√°metros, los suma (3+5=8) y retorna 8. Luego print(8) muestra '8' en la salida.",
  "points": 10
}}"""
        
        prompt = f"""Genera EXACTAMENTE {num_questions} preguntas de opci√≥n m√∫ltiple sobre {topic} de {diff_info['description']}.

üéØ OBJETIVO: Crear {num_questions} preguntas de ALTA CALIDAD que eval√∫en comprensi√≥n real del tema.{code_instructions}

‚è±Ô∏è TIEMPO SUGERIDO PARA ESTA EVALUACI√ìN: {int(suggested_time)} minutos
   (Aproximadamente {diff_info['min_time_per_question']}-{diff_info['max_time_per_question']} minutos por pregunta para {diff_info['description']})

üî¥ CRITERIOS DE CALIDAD PARA {diff_info['description'].upper()}:

1. **Relevancia t√©cnica**: {diff_info['details']}
2. **Profundidad adecuada**: Las preguntas deben requerir {diff_info['min_time_per_question']}-{diff_info['max_time_per_question']} minutos de an√°lisis
3. **Opciones desafiantes**: Los distractores deben ser plausibles pero incorrectos
4. **Variedad**: Incluye diferentes aspectos de {topic}

üìã TIPOS DE PREGUNTAS A INCLUIR (distribuir entre las {num_questions}):
- 30-40%: Conceptos te√≥ricos aplicados
- 30-40%: An√°lisis de c√≥digo/escenarios
- 20-30%: Mejores pr√°cticas y comparaciones
- 10-20%: Casos edge y debugging

IMPORTANTE: Responde √öNICAMENTE con un JSON v√°lido, sin texto adicional antes o despu√©s.

Formato JSON requerido:
{{
  "questions": [
    {{
      "question_text": "Pregunta detallada que requiera an√°lisis (m√≠nimo 50 caracteres)",
      "code_snippet": "# C√≥digo relevante (OPCIONAL, pero REQUERIDO si include_code_snippets=true)\\ndef ejemplo():\\n    return 42",
      "question_type": "MULTIPLE_CHOICE",
      "options": ["Opci√≥n A detallada", "Opci√≥n B detallada", "Opci√≥n C detallada", "Opci√≥n D detallada"],
      "correct_answer": "0",
      "explanation": "Explicaci√≥n completa de por qu√© es correcta Y por qu√© las otras son incorrectas (m√≠nimo 100 caracteres)",
      "points": 10
    }}
  ],
  "suggested_time_minutes": {int(suggested_time)},
  "difficulty_level": "{difficulty}",
  "topic": "{topic}"
}}{code_example}

üö´ EVITA (ERRORES COMUNES):
- ‚ùå Preguntas que se responden con "s√≠/no" obvios
- ‚ùå Definiciones memorizables sin contexto
- ‚ùå Opciones claramente incorrectas o rid√≠culas
- ‚ùå Preguntas demasiado simples para {diff_info['description']}
- ‚ùå Explicaciones vagas o incompletas
‚úÖ BUSCA (BUENAS PR√ÅCTICAS):
- ‚úÖ Preguntas que requieran razonamiento
- ‚úÖ Escenarios realistas del mundo real
- ‚úÖ Opciones que distingan conocimiento superficial vs profundo
- ‚úÖ Explicaciones que ense√±en conceptos adicionales
- ‚úÖ Preguntas que eval√∫en comprensi√≥n, no memorizaci√≥n

REGLAS OBLIGATORIAS:
- Cada pregunta debe tener EXACTAMENTE 4 opciones
- correct_answer debe ser el √≠ndice (0-3) de la opci√≥n correcta
- question_text debe tener M√çNIMO 50 caracteres
- explanation debe tener M√çNIMO 100 caracteres y explicar por qu√© las otras opciones son incorrectas
- Todas las opciones deben ser gramaticalmente completas y profesionales
- Var√≠a la posici√≥n de la respuesta correcta (no siempre en √≠ndice 0)
- Idioma: {'espa√±ol' if language == 'es' else 'ingl√©s'}

üìä DISTRIBUCI√ìN DE COMPLEJIDAD DENTRO DE {diff_info['description']}:
- 20% m√°s f√°ciles (entrada al nivel)
- 60% complejidad est√°ndar del nivel
- 20% m√°s desafiantes (techo del nivel)

EJEMPLO DE PREGUNTA DE CALIDAD PARA {diff_info['description']}:
{{
  "question_text": "En una aplicaci√≥n React, tienes un componente que renderiza una lista de 10,000 elementos y notas problemas de rendimiento. ¬øCu√°l estrategia de optimizaci√≥n ser√≠a M√ÅS efectiva?",
  "question_type": "MULTIPLE_CHOICE",
  "options": [
    "Usar React.memo() en el componente de lista completo",
    "Implementar virtualizaci√≥n con react-window para renderizar solo elementos visibles",
    "Agregar key props a cada elemento de la lista",
    "Usar useCallback en todos los event handlers"
  ],
  "correct_answer": "1",
  "explanation": "La virtualizaci√≥n (opci√≥n B) es la m√°s efectiva porque renderiza solo los elementos visibles en el viewport, reduciendo dr√°sticamente el DOM. React.memo ayuda pero no resuelve el problema de 10,000 elementos montados. Las keys son necesarias pero no mejoran el rendimiento significativamente. useCallback optimiza re-renders pero no reduce la cantidad de elementos.",
  "points": 10
}}

Ahora genera EXACTAMENTE {num_questions} preguntas de {diff_info['description']} sobre {topic}:
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": f"Eres un experto senior en crear evaluaciones t√©cnicas de programaci√≥n de {diff_info['description']}. DEBES generar EXACTAMENTE {num_questions} preguntas. Respondes SOLO con JSON v√°lido. Tus preguntas son desafiantes, relevantes y bien fundamentadas."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,  # Aumentado para m√°s creatividad y variedad
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            questions = result.get("questions", [])
            
            # Validaci√≥n: asegurar que se generaron suficientes preguntas
            if len(questions) < num_questions:
                print(f"‚ö†Ô∏è ADVERTENCIA: Se generaron solo {len(questions)} de {num_questions} preguntas solicitadas")
            
            # A√±adir metadata de tiempo sugerido a cada pregunta
            for question in questions:
                if "suggested_time_minutes" not in question:
                    question["suggested_time_minutes"] = (diff_info["min_time_per_question"] + diff_info["max_time_per_question"]) / 2
            
            return questions
            
        except Exception as e:
            raise Exception(f"Error al generar preguntas con OpenAI: {str(e)}")
    
    def generate_coding_challenges(self, topic, difficulty="MEDIUM", num_challenges=1, language="python"):
        """
        Genera desaf√≠os de c√≥digo pr√°ctico con test_cases autom√°ticos para sandbox
        
        Args:
            topic: Tema t√©cnico
            difficulty: EASY, MEDIUM, HARD
            num_challenges: Cantidad de desaf√≠os (por defecto 1)
            language: Lenguaje de programaci√≥n (python, javascript, java, etc.)
            
        Returns:
            Lista de diccionarios con desaf√≠os de c√≥digo y test_cases
        """
        difficulty_map = {
            "EASY": "b√°sico, sintaxis fundamental",
            "MEDIUM": "intermedio, estructuras de datos y algoritmos",
            "HARD": "avanzado, optimizaci√≥n y patrones complejos"
        }
        
        # Ejemplos de sintaxis seg√∫n lenguaje
        language_examples = {
            "python": {
                "snippet": "def solution(param):\\n    # Tu c√≥digo aqu√≠\\n    pass",
                "input_example": '"[1, 2, 3]"',
                "output_example": '"6"',
                "note": "Test_cases para Python sandbox - formato JSON est√°ndar",
                "example_one_param": '{"input": "[1, 2, 3]", "expected_output": "6"}',
                "example_multi_param": '{"input": "[[1, 2, 3], 5]", "expected_output": "[1, 2, 3, 5]"}'
            },
            "javascript": {
                "snippet": "function solution(param) {\\n  // Tu c√≥digo aqu√≠\\n}",
                "input_example": '"[1, 2, 3]"',
                "output_example": '"6"',
                "note": "Test_cases para JavaScript sandbox - formato JSON est√°ndar",
                "example_one_param": '{"input": "[1, 2, 3]", "expected_output": "6"}',
                "example_multi_param": '{"input": "[[1, 2, 3], 5]", "expected_output": "[1, 2, 3, 5]"}'
            },
            "java": {
                "snippet": "public class Solution {\\n  public static int solution(int[] param) {\\n    // Tu c√≥digo aqu√≠\\n    return 0;\\n  }\\n}",
                "input_example": '"[1, 2, 3]"',
                "output_example": '"6"',
                "note": "Test_cases para Java sandbox - formato JSON est√°ndar",
                "example_one_param": '{"input": "[1, 2, 3]", "expected_output": "6"}',
                "example_multi_param": '{"input": "[[1, 2, 3], 5]", "expected_output": "[1, 2, 3, 5]"}'
            }
        }
        
        lang_info = language_examples.get(language.lower(), language_examples["python"])
        
        prompt = f"""Genera {num_challenges} desaf√≠os de programaci√≥n en {language} sobre {topic} de nivel {difficulty_map.get(difficulty, 'intermedio')}.

üéØ OBJETIVO: Crear desaf√≠os educativos con test_cases que se ejecutar√°n en un SANDBOX REAL.

IMPORTANTE: Responde √öNICAMENTE con un JSON v√°lido, sin texto adicional.

Formato JSON requerido:
{{
  "challenges": [
    {{
      "question_text": "Descripci√≥n clara del problema a resolver",
      "question_type": "CODE",
      "programming_language": "{language}",
      "code_snippet": "{lang_info['snippet']}",
      "test_cases": [
        {{
          "description": "Descripci√≥n del caso de prueba",
          "input": "STRING JSON con los par√°metros",
          "expected_output": "STRING JSON con el resultado esperado"
        }}
      ],
      "explanation": "Explicaci√≥n de la soluci√≥n √≥ptima",
      "points": 20
    }}
  ]
}}

üî¥ REGLAS CR√çTICAS PARA TEST_CASES (muy importante):

1. **Cantidad**: Genera M√çNIMO 4 test_cases, IDEAL 5-6 test_cases por desaf√≠o

2. **Cobertura**: Los test_cases DEBEN cubrir:
   - ‚úÖ Caso b√°sico/feliz (entrada t√≠pica)
   - ‚úÖ Caso edge (array vac√≠o, string vac√≠o, null, 0, etc.)
   - ‚úÖ Caso con m√∫ltiples elementos
   - ‚úÖ Caso l√≠mite (n√∫meros grandes, strings largos)
   - ‚úÖ Caso especial del dominio del problema

3. **Formato de input y expected_output** (MUY IMPORTANTE):
   - AMBOS deben ser STRINGS JSON v√°lidos
   - Para UN par√°metro:
     * N√∫mero: "42" o "3.14"
     * String: "\\"texto\\"" (con escapes)
     * Array: "[1, 2, 3]"
     * Boolean: "true" o "false"
     * Null: "null"
   - Para M√öLTIPLES par√°metros: usar un ARRAY que contenga todos los par√°metros:
     * Dos n√∫meros: "[5, 10]"
     * Array y n√∫mero: "[[1, 2, 3, 4, 5], 6]"
     * String y n√∫mero: "[\\"hello\\", 3]"
     * Tres par√°metros: "[param1, param2, param3]"
   
   ‚ö†Ô∏è REGLA CR√çTICA: Si la funci√≥n recibe m√∫ltiples par√°metros, el input DEBE ser un array: "[param1, param2]"
   ‚ùå INCORRECTO: "[1, 2, 3], 6" (esto NO es JSON v√°lido)
   ‚úÖ CORRECTO: "[[1, 2, 3], 6]" (array con dos elementos)

4. **Nota para {language}**: {lang_info['note']}

5. **code_snippet**: Debe ser una plantilla inicial √∫til pero sin resolver el problema

6. **Problemas realistas**: Crea desaf√≠os educativos, pr√°cticos y relevantes para {topic}

EJEMPLO CORRECTO ({language.upper()} - UN PAR√ÅMETRO):
{{
  "challenges": [
    {{
      "question_text": "Crea una funci√≥n que sume todos los n√∫meros pares de un array",
      "question_type": "CODE",
      "programming_language": "{language}",
      "code_snippet": "{lang_info['snippet']}",
      "test_cases": [
        {{
          "description": "Array con n√∫meros mixtos",
          "input": "[1, 2, 3, 4, 5, 6]",
          "expected_output": "12"
        }},
        {{
          "description": "Array vac√≠o",
          "input": "[]",
          "expected_output": "0"
        }},
        {{
          "description": "Solo n√∫meros impares",
          "input": "[1, 3, 5, 7]",
          "expected_output": "0"
        }},
        {{
          "description": "Solo n√∫meros pares",
          "input": "[2, 4, 6, 8]",
          "expected_output": "20"
        }},
        {{
          "description": "Array con un solo elemento par",
          "input": "[10]",
          "expected_output": "10"
        }},
        {{
          "description": "Array con n√∫meros negativos",
          "input": "[-4, -2, 1, 3]",
          "expected_output": "-6"
        }}
      ],
      "explanation": "La soluci√≥n √≥ptima usa filter() para n√∫meros pares y reduce() para sumar. Complejidad O(n) temporal, O(1) espacial.",
      "points": 20
    }}
  ]
}}

EJEMPLO CORRECTO ({language.upper()} - DOS PAR√ÅMETROS):
{{
  "challenges": [
    {{
      "question_text": "Crea una funci√≥n que filtre n√∫meros pares de un array y retorne solo los primeros N elementos",
      "question_type": "CODE",
      "programming_language": "{language}",
      "code_snippet": "{lang_info['snippet']}",
      "test_cases": [
        {{
          "description": "Array con n√∫meros mixtos y l√≠mite 2",
          "input": "[[1, 2, 3, 4, 5, 6], 2]",
          "expected_output": "[2, 4]"
        }},
        {{
          "description": "Array vac√≠o",
          "input": "[[], 3]",
          "expected_output": "[]"
        }},
        {{
          "description": "L√≠mite mayor que pares disponibles",
          "input": "[[2, 4, 6], 10]",
          "expected_output": "[2, 4, 6]"
        }},
        {{
          "description": "Solo impares con l√≠mite",
          "input": "[[1, 3, 5], 2]",
          "expected_output": "[]"
        }}
      ],
      "explanation": "Filtrar los pares y luego usar slice(0, limite). Complejidad O(n).",
      "points": 20
    }}
  ]
}}

‚ö†Ô∏è VERIFICACI√ìN FINAL:
- Cada test_case tiene "description", "input" (string JSON), "expected_output" (string JSON)
- Los valores de input y expected_output est√°n entre comillas y son strings JSON v√°lidos
- Hay al menos 4-6 test_cases por desaf√≠o
- Los test_cases cubren casos normales, edge cases y casos l√≠mite
- El nivel de dificultad es {difficulty_map.get(difficulty)}
- Los test_cases son COMPATIBLES con sandbox de {language} (Piston API, e0.gg, etc.)
- El formato de input/output es UNIVERSAL y funciona en cualquier sandbox

IMPORTANTE: Los test_cases generados deben ser ejecutables en sandboxes reales para {language}.
El formato JSON debe ser compatible con APIs de ejecuci√≥n de c√≥digo como Piston API.

Ahora genera los {num_challenges} desaf√≠os sobre {topic} en {language}:
"""
        
        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": f"Eres un experto en crear desaf√≠os de programaci√≥n en {language}. Respondes SOLO con JSON v√°lido."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            return result.get("challenges", [])
            
        except Exception as e:
            raise Exception(f"Error al generar desaf√≠os con OpenAI: {str(e)}")
    
    def evaluate_code_answer(self, question_text, candidate_code, test_cases, language="python", difficulty="MEDIUM"):
        """
        Eval√∫a una respuesta de c√≥digo usando OpenAI
        
        Args:
            question_text: Enunciado de la pregunta
            candidate_code: C√≥digo enviado por el candidato
            test_cases: Lista de casos de prueba
            language: Lenguaje de programaci√≥n
            difficulty: Nivel de dificultad (EASY, MEDIUM, HARD)
            
        Returns:
            Dict con evaluaci√≥n y feedback
        """
        
        # Mapeo de dificultad a criterios de evaluaci√≥n
        difficulty_criteria = {
            "EASY": {
                "funcionalidad": 70,
                "correctitud": 15,
                "legibilidad": 10,
                "eficiencia": 5,
                "min_score": 80,  # Si pasa todos los tests
                "description": "nivel B√ÅSICO/F√ÅCIL"
            },
            "MEDIUM": {
                "funcionalidad": 60,
                "correctitud": 20,
                "legibilidad": 10,
                "eficiencia": 10,
                "min_score": 75,  # Si pasa todos los tests
                "description": "nivel INTERMEDIO"
            },
            "HARD": {
                "funcionalidad": 50,
                "correctitud": 25,
                "legibilidad": 10,
                "eficiencia": 15,
                "min_score": 70,  # Si pasa todos los tests
                "description": "nivel AVANZADO"
            }
        }
        
        criteria = difficulty_criteria.get(difficulty, difficulty_criteria["MEDIUM"])
        
        prompt = f"""Eval√∫a el siguiente c√≥digo del candidato para un ejercicio de {criteria['description']}:

PREGUNTA:
{question_text}

C√ìDIGO DEL CANDIDATO ({language}):
```{language}
{candidate_code}
```

CASOS DE PRUEBA:
{json.dumps(test_cases, indent=2)}

üéØ ESCALA DE PUNTAJES QUE DEBES USAR:
- Si el c√≥digo funciona y pasa TODOS los tests ‚Üí M√çNIMO {criteria['min_score']}% (hasta 100%)
- Si el c√≥digo funciona y pasa la mayor√≠a de tests ‚Üí 60-{criteria['min_score']-1}%
- Si el c√≥digo funciona parcialmente ‚Üí 40-59%
- Si el c√≥digo tiene errores graves ‚Üí 0-39%

üìä CRITERIOS (usa estos pesos):
1. FUNCIONALIDAD ({criteria['funcionalidad']}%): ¬øFunciona? ¬øPasa los tests?
2. CORRECTITUD ({criteria['correctitud']}%): ¬øLa l√≥gica es correcta?
3. LEGIBILIDAD ({criteria['legibilidad']}%): ¬øEs claro?
4. EFICIENCIA ({criteria['eficiencia']}%): ¬øEs razonable?

‚ö†Ô∏è REGLAS OBLIGATORIAS:
‚úÖ Si "is_correct": true ‚Üí el "score_percentage" DEBE ser M√çNIMO {criteria['min_score']}%
‚úÖ Si TODOS los "test_results" tienen "passed": true ‚Üí M√çNIMO {criteria['min_score']}%
‚úÖ NO seas demasiado estricto con c√≥digo que funciona correctamente
‚úÖ Este es {criteria['description']}, ajusta expectativas seg√∫n el nivel

Responde SOLO con JSON:
{{
  "is_correct": true/false,
  "score_percentage": N√öMERO_ENTRE_0_Y_100,
  "feedback": "An√°lisis del c√≥digo destacando fortalezas primero",
  "strengths": ["fortaleza 1", "fortaleza 2"],
  "improvements": ["sugerencia 1", "sugerencia 2"],
  "test_results": [
    {{"test_case": 1, "passed": true/false, "message": "resultado del test 1"}},
    {{"test_case": 2, "passed": true/false, "message": "resultado del test 2"}}
  ]
}}

RECORDATORIO FINAL: Si marcas "is_correct": true, el score_percentage NO puede ser menor a {criteria['min_score']}."""

        try:
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": f"Eres un evaluador de c√≥digo {language}. REGLA CR√çTICA: Si el c√≥digo funciona correctamente (is_correct=true), el score_percentage DEBE ser M√çNIMO {criteria['min_score']}%. Si todos los tests pasan, M√çNIMO {criteria['min_score']}%. Respondes SOLO JSON v√°lido. S√© JUSTO y GENEROSO con c√≥digo funcional."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,  # M√°s determin√≠stico para puntajes consistentes
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # ‚ö°‚ö°‚ö° VALIDACI√ìN ULTRA ROBUSTA: M√öLTIPLES CAPAS DE VERIFICACI√ìN ‚ö°‚ö°‚ö°
            score = result.get("score_percentage", 0)
            is_correct = result.get("is_correct", False)
            test_results = result.get("test_results", [])
            
            # Contar tests que pasaron
            passed_count = 0
            total_count = len(test_results) if test_results else 0
            if test_results:
                passed_count = sum(1 for t in test_results if t.get("passed", False))
            
            all_tests_passed = (total_count > 0 and passed_count == total_count)
            
            # üî¥ CAPA 1: Si is_correct es true, FORZAR puntaje m√≠nimo
            if is_correct:
                if score < criteria["min_score"]:
                    result["score_percentage"] = criteria["min_score"]
                    result["feedback"] = f"‚úÖ C√≥digo correcto que resuelve el problema. {result.get('feedback', '')}"
            
            # üî¥ CAPA 2: Si todos los tests pasaron, FORZAR puntaje m√≠nimo
            if all_tests_passed:
                if score < criteria["min_score"]:
                    result["score_percentage"] = criteria["min_score"]
                    result["is_correct"] = True
                    result["feedback"] = f"‚úÖ TODOS los tests pasaron ({passed_count}/{total_count}). {result.get('feedback', '')}"
            
            # üî¥ CAPA 3: Si pasa m√°s del 80% de tests, dar al menos 70%
            if total_count > 0:
                pass_rate = (passed_count / total_count) * 100
                if pass_rate >= 80 and score < 70:
                    result["score_percentage"] = max(70, score)
                    result["is_correct"] = pass_rate == 100
            
            # üî¥ CAPA 4: Verificaci√≥n final cruzada
            final_score = result.get("score_percentage", 0)
            final_is_correct = result.get("is_correct", False)
            
            if final_is_correct and final_score < criteria["min_score"]:
                result["score_percentage"] = criteria["min_score"]
            
            if all_tests_passed and final_score < criteria["min_score"]:
                result["score_percentage"] = criteria["min_score"]
                result["is_correct"] = True
            
            # üî¥ CAPA 5: Garant√≠a absoluta - √∫ltima verificaci√≥n
            ultimate_score = result.get("score_percentage", 0)
            if all_tests_passed and ultimate_score < criteria["min_score"]:
                # Si TODOS los tests pasaron, NO PUEDE ser menos del m√≠nimo
                result["score_percentage"] = criteria["min_score"]
                result["is_correct"] = True
                print(f"‚ö†Ô∏è CORRECCI√ìN FORZADA: Score original {score}% -> {criteria['min_score']}% (todos los tests pasaron)")
            
            return result
            
        except Exception as e:
            raise Exception(f"Error al evaluar c√≥digo con OpenAI: {str(e)}")
    
    def analyze_application_for_assessment(self, application_id):
        """
        Analiza una aplicaci√≥n (candidato + proyecto) y sugiere par√°metros para crear una evaluaci√≥n
        
        Args:
            application_id: ID de la Application a analizar
            
        Returns:
            Dict con sugerencias para crear evaluaci√≥n t√©cnica
        """
        from recruiting.models import Application
        from projects.models import Project
        from django.contrib.auth.models import User
        import datetime
        
        try:
            # 1. Obtener la aplicaci√≥n
            application = Application.objects.select_related('candidate', 'project').get(id=application_id)
            project = application.project
            candidate = application.candidate
            
            # 2. Extraer informaci√≥n relevante
            required_skills = project.required_skills if hasattr(project, 'required_skills') else []
            extracted_data = application.extracted if application.extracted else {}
            candidate_skills = extracted_data.get('skills', [])
            experience_years = extracted_data.get('experience_years', 0)
            
            # Obtener texto del CV (primeros 500 caracteres)
            cv_preview = ""
            if application.parsed_text:
                cv_preview = application.parsed_text[:500]
            
            # 3. Construir prompt para OpenAI
            prompt = f"""Eres un experto en recursos humanos t√©cnicos. Analiza la siguiente informaci√≥n y sugiere par√°metros √≥ptimos para una evaluaci√≥n t√©cnica.

PROYECTO:
- T√≠tulo: {project.title}
- Descripci√≥n: {project.description[:200] if project.description else 'No disponible'}
- Skills requeridos: {', '.join(required_skills) if required_skills else 'No especificados'}
- Prioridad: {project.priority if hasattr(project, 'priority') else 'Media'}

CANDIDATO:
- Username: {candidate.username}
- A√±os de experiencia detectados: {experience_years}
- Skills del CV: {', '.join(candidate_skills) if candidate_skills else 'No detectados'}
- Match score con proyecto: {application.match_score}%
- Resumen CV: {cv_preview if cv_preview else 'No disponible'}

CONTEXTO ADICIONAL:
- Estado aplicaci√≥n: {application.status}
- Fecha aplicaci√≥n: {application.created_at.strftime('%Y-%m-%d') if application.created_at else 'N/A'}

INSTRUCCIONES:
Bas√°ndote en el an√°lisis anterior, sugiere:
1. **T√≠tulo descriptivo** para la evaluaci√≥n (m√°x 100 caracteres)
2. **Descripci√≥n breve** explicando enfoque (m√°x 200 caracteres)
3. **Tipo de evaluaci√≥n**: "QUIZ" (preguntas te√≥ricas) o "CODING" (prueba de c√≥digo)
4. **Dificultad**: "EASY" (junior/b√°sico), "MEDIUM" (mid-level/intermedio), "HARD" (senior/avanzado)
5. **Tiempo en minutos**: entre 30-120 seg√∫n complejidad
6. **Score m√≠nimo para aprobar**: entre 60-85%
7. **N√∫mero de preguntas**: 5-15 (menos para CODING, m√°s para QUIZ)
8. **Lenguaje de programaci√≥n** principal (si tipo es CODING)
9. **Nivel de experiencia del candidato**: "junior", "intermediate", "senior"
10. **Complejidad del proyecto**: "low", "medium", "high"
11. **Skills detectados** m√°s relevantes para esta evaluaci√≥n

CRITERIOS DE DECISI√ìN:
- Si match_score >= 80% ‚Üí EASY (candidato califica bien)
- Si match_score 60-79% ‚Üí MEDIUM (candidato promedio)
- Si match_score < 60% ‚Üí HARD (evaluar m√°s a fondo)
- Si required_skills incluye lenguajes de programaci√≥n ‚Üí CODING
- Si required_skills son principalmente soft skills o te√≥ricos ‚Üí QUIZ
- Ajustar tiempo seg√∫n dificultad y cantidad de preguntas:
  * QUIZ EASY: 2-3 min/pregunta ‚Üí 8-12 preguntas = 30-45 min
  * QUIZ MEDIUM: 3-5 min/pregunta ‚Üí 10-15 preguntas = 45-75 min
  * QUIZ HARD: 5-7 min/pregunta ‚Üí 12-20 preguntas = 60-120 min
  * CODING EASY: 1-2 desaf√≠os = 30-45 min
  * CODING MEDIUM: 2-3 desaf√≠os = 60-90 min
  * CODING HARD: 3-5 desaf√≠os = 90-120 min
- Score m√≠nimo: EASY=65%, MEDIUM=70%, HARD=75%
- Para QUIZ: M√çNIMO 8 preguntas, IDEAL 10-15 preguntas
- Para CODING: 1-5 desaf√≠os seg√∫n dificultad

RESPONDE EN JSON con esta estructura EXACTA:
{{
  "suggested_title": "...",
  "suggested_description": "...",
  "suggested_type": "QUIZ",
  "suggested_difficulty": "MEDIUM",
  "suggested_time_minutes": 60,
  "suggested_passing_score": 70,
  "suggested_num_questions": 10,
  "suggested_programming_language": "JavaScript",
  "difficulty_reason": "Explicaci√≥n de por qu√© esta dificultad es apropiada",
  "time_reason": "Explicaci√≥n de por qu√© este tiempo es adecuado",
  "score_reason": "Explicaci√≥n del score m√≠nimo sugerido",
  "type_reason": "Explicaci√≥n de por qu√© QUIZ o CODING",
  "detected_skills": ["skill1", "skill2", "skill3"],
  "candidate_experience_level": "intermediate",
  "project_complexity": "medium"
}}"""

            # 4. Llamar a OpenAI
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "Eres un experto en recursos humanos t√©cnicos especializado en crear evaluaciones. Respondes √öNICAMENTE con JSON v√°lido."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            result = json.loads(response.choices[0].message.content)
            
            # Validar y normalizar resultado
            result['application_id'] = application_id
            result['analyzed_at'] = datetime.datetime.now().isoformat()
            
            return result
            
        except Application.DoesNotExist:
            raise ValueError(f"Application {application_id} no encontrada")
        except Exception as e:
            # Si OpenAI falla, usar l√≥gica de fallback
            print(f"‚ö†Ô∏è OpenAI fall√≥, usando fallback: {str(e)}")
            return self._get_fallback_suggestions(application_id)
    
    def _get_fallback_suggestions(self, application_id):
        """
        L√≥gica de fallback si OpenAI no est√° disponible
        Usa reglas heur√≠sticas para generar sugerencias
        """
        from recruiting.models import Application
        import datetime
        
        try:
            application = Application.objects.select_related('candidate', 'project').get(id=application_id)
            project = application.project
            
            # Determinar dificultad basada en match_score
            if application.match_score >= 80:
                difficulty = "EASY"
                passing_score = 65
                time_minutes = 40
                num_questions_quiz = 10
                num_questions_coding = 2
            elif application.match_score >= 60:
                difficulty = "MEDIUM"
                passing_score = 70
                time_minutes = 60
                num_questions_quiz = 12
                num_questions_coding = 3
            else:
                difficulty = "HARD"
                passing_score = 75
                time_minutes = 90
                num_questions_quiz = 15
                num_questions_coding = 4
            
            # Determinar tipo basado en skills requeridos
            required_skills = project.required_skills if hasattr(project, 'required_skills') else []
            coding_keywords = ['react', 'python', 'java', 'javascript', 'node', 'django', 'angular', 
                             'vue', 'php', 'ruby', 'go', 'rust', 'c++', 'c#', 'swift', 'kotlin']
            has_coding = any(
                any(keyword in str(skill).lower() for keyword in coding_keywords)
                for skill in required_skills
            )
            
            assessment_type = "CODING" if has_coding else "QUIZ"
            num_questions = num_questions_coding if assessment_type == "CODING" else num_questions_quiz
            
            # Detectar lenguaje principal
            programming_language = "JavaScript"
            for skill in required_skills:
                skill_lower = str(skill).lower()
                if 'python' in skill_lower or 'django' in skill_lower:
                    programming_language = "Python"
                    break
                elif 'java' in skill_lower and 'javascript' not in skill_lower:
                    programming_language = "Java"
                    break
                elif 'react' in skill_lower or 'node' in skill_lower or 'javascript' in skill_lower:
                    programming_language = "JavaScript"
                    break
            
            # Determinar nivel de experiencia
            extracted = application.extracted if application.extracted else {}
            experience_years = extracted.get('experience_years', 0)
            if experience_years < 2:
                candidate_experience = "junior"
            elif experience_years < 5:
                candidate_experience = "intermediate"
            else:
                candidate_experience = "senior"
            
            # Complejidad del proyecto
            if project.priority <= 2:
                project_complexity = "high"
            elif project.priority <= 3:
                project_complexity = "medium"
            else:
                project_complexity = "low"
            
            # Detectar skills relevantes
            detected_skills = required_skills[:5] if required_skills else ["No especificados"]
            
            return {
                "suggested_title": f"Evaluaci√≥n {project.title}",
                "suggested_description": f"Evaluaci√≥n t√©cnica para proyecto {project.title} - Nivel {difficulty.lower()}",
                "suggested_type": assessment_type,
                "suggested_difficulty": difficulty,
                "suggested_time_minutes": time_minutes,
                "suggested_passing_score": passing_score,
                "suggested_num_questions": num_questions,
                "suggested_programming_language": programming_language if assessment_type == "CODING" else None,
                "difficulty_reason": f"Match score de {application.match_score}% sugiere nivel {difficulty}",
                "time_reason": f"Dificultad {difficulty} requiere aproximadamente {time_minutes} minutos",
                "score_reason": f"Score m√≠nimo de {passing_score}% apropiado para nivel {difficulty}",
                "type_reason": f"{'Skills de programaci√≥n detectados' if has_coding else 'Skills principalmente te√≥ricos'} sugieren {assessment_type}",
                "detected_skills": detected_skills,
                "candidate_experience_level": candidate_experience,
                "project_complexity": project_complexity,
                "application_id": application_id,
                "analyzed_at": datetime.datetime.now().isoformat(),
                "fallback_used": True
            }
            
        except Application.DoesNotExist:
            raise ValueError(f"Application {application_id} no encontrada")
        except Exception as e:
            raise Exception(f"Error en fallback: {str(e)}")